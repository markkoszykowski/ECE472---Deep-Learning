# -*- coding: utf-8 -*-
"""Assignment 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AZckcdsu7Z0o-GpAh274aAca3c01gmBm
"""

## Mark Koszykowski
## ECE472 - Deep Learning
## Assignment 1

import numpy as np
import matplotlib.pyplot as plt
import jax
import jax.numpy as jnp
from jax import grad

from google.colab import files

# Define a Phi function which is simply a Normal Distribution
def phi(x, mu, SD):
    return jnp.exp(-(x - mu)**2 / SD ** 2)

# Define a function which calculates the y_hat
def f(params, x, M):
    y_hat = jnp.zeros(len(x))

    for i in range(M):
        y_hat += params["w" + str(i)] * phi(x, params["mu" + str(i)], params["SD" + str(i)])

    y_hat += params["b"]

    return y_hat

# Define a loss function which calculates average difference
def loss(params, x, y, M):
    y_hat = f(params, x, M)

    # Scalar of 1/2 not necessary however was included in assignment so was included for redundancy
    return jnp.mean((1/2) * (y - y_hat) ** 2)

# Define a step function which adjusts th parameters
def step(params, step_size, x, y, M):
    g = grad(loss)(params, x, y, M)
    
    return step_size, {k: params[k] - step_size * g[k] for k, v in params.items()}

# Define general variables of problem
N = 50
sigma = 0.1

# M chosen based on minimum value at which there seemed to be no change in curve shape
M = 10

step_size = 0.1

# Setup a dictioanry of parameters and initialize to pseudo-random values
params = dict()
for i in range(M):
    params["mu" + str(i)] = 0.1 * (i + 1)
    params["SD" + str(i)] = 0.1 * (i + 1)
    params["w" + str(i)] = 0.1 * (i + 1)
params["b"] = 0.1

# Create the noisy data points
x = np.random.uniform(size=N)
y = np.sin(2*np.pi*x) + np.random.normal(scale=sigma, size=N)

# Create a noiseless wave function
x_noiseless = jnp.linspace(0, 1, 1000)
y_noiseless = jnp.sin(2*np.pi*x_noiseless)

# Iterate step function to adjust the dictionary of parameters
                                                              
  _, params = step(params, step_size, x, y, M)

# Print out all the parameters to be optimized line-by-line
for k,v in params.items():
  print(k, " = ", v)

# Create a plot of asked for information
fig1 = plt.figure()
plt.plot(x, y, 'x', label='Noisy Data Points')
plt.plot(x_noiseless, y_noiseless, label='Noiseless Curve')
plt.plot(x_noiseless, f(params, x_noiseless, M), '--', label='Regression Model')
plt.legend()
plt.title("Fit 1")
plt.xlabel("x")
plt.ylabel("y", rotation=0)
fig1.show()
fig1.savefig('Fit1.pdf')
files.download('Fit1.pdf')

# Create a plot of the individual Normal Distributions
fig2 = plt.figure()
for i in range(M):
    plt.plot(x_noiseless, phi(x_noiseless, params["mu" + str(i)], params["SD" + str(i)]), label='ND #' + str(i+1))
plt.legend()
plt.title("Bases for Fit 1")
plt.xlabel("x")
plt.ylabel("y", rotation=0)
fig2.show()
fig2.savefig('BasesforFit1.pdf')
files.download('BasesforFit1.pdf')
